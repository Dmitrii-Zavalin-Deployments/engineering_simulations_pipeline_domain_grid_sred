name: Fluid Data Processing and Commit

on:
  push:
    branches:
      - "**"  # Runs on any branch
  workflow_dispatch:

jobs:
  process_fluid_data:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: List Repository Contents
        run: ls -R # This will now show initial_data.json in data/testing-input-output/

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"  # Test only Python 3.11 for easier debugging

      - name: Upgrade pip
        run: python -m pip install --upgrade pip

      - name: Verify requirements.txt exists
        run: |
          if [ ! -f "$GITHUB_WORKSPACE/requirements.txt" ]; then
            echo "❌ Error: requirements.txt not found!"
            exit 1
          fi

      - name: Install system dependencies (Keep TBB if needed)
        run: |
          sudo apt-get update
          sudo apt-get install -y libtbb-dev

      - name: Install Python dependencies (NumPy, HDF5, SciPy)
        # Assuming these are sufficient. If your simulation/post-processing needs more, add them to requirements.txt
        # and use 'pip install -r requirements.txt' instead.
        run: |
          pip install --upgrade numpy h5py scipy pytest

      - name: Debug Dependencies (Check NumPy, HDF5, SciPy)
        run: |
          python -c "import numpy, h5py, scipy" || echo "⚠️ Missing dependencies!"

      - name: Run Fluid Data Post-processing Script
        # This script processes the JSON output and generates .npy files
        # It will now correctly look for initial_data.json in data/testing-input-output/
        run: python "$GITHUB_WORKSPACE/src/post_process_simulation_results.py"

      # - name: Run tests
      #   # The tests should ideally run after the data generation to ensure they can use the latest data
      #   run: pytest tests --verbose || echo "⚠️ Some tests failed, but workflow continues."

      - name: Debug Directory Structure Before Commit
        run: ls -R $GITHUB_WORKSPACE

      - name: Commit new fluid simulation outputs
        env:
          GIT_USER_NAME: ${{ secrets.GIT_USER_NAME }}
          GIT_USER_EMAIL: ${{ secrets.GIT_USER_EMAIL }}
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"

          cd "$GITHUB_WORKSPACE"
          
          # Add the new .npy files and metadata JSON from the correct directory
          if ls data/testing-input-output/*.npy 1> /dev/null 2>&1; then
              git add data/testing-input-output/*.npy
          else
              echo "ℹ️ No .npy files to add."
          fi

          if ls data/testing-input-output/*.json 1> /dev/null 2>&1; then
              git add data/testing-input-output/*.json
          else
              echo "ℹ️ No .json files to add."
          fi

          # Remove obsolete Blender JSON output if it is no longer used
          git rm -f data/testing-input-output/blender_fluid_parameters.json || echo "Already removed."

          # If the external solver commits navier_stokes_results.json, it should be committed too.
          # If initial_data.json is part of this repo's input, you might want to add it too.
          git add data/testing-input-output/initial_data.json || echo "ℹ️ No initial_data.json to add."
          git add data/testing-input-output/navier_stokes_results.json || echo "ℹ️ No navier_stokes_results.json to add."

          git commit -m "Auto-update: Fluid simulation outputs and processed data (using initial_data.json)" || echo "No changes to commit."
          git push origin HEAD
